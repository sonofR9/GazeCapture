{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MyGazeTryWorking.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ImV5F3oRmg3i"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import argparse\n",
        "import timeit\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H10RJwMsH3WT",
        "outputId": "e079c623-3a3a-430a-915a-5ccd9fa755e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Network Parameters\n",
        "img_size = 64\n",
        "n_channel = 3\n",
        "mask_size = 25\n",
        "# pathway: eye_left and eye_right\n",
        "conv1_eye_size = 11\n",
        "conv1_eye_out = 96\n",
        "pool_eye_size = 2\n",
        "pool_eye_stride = 2\n",
        "conv2_eye_size = 5\n",
        "conv2_eye_out = 256\n",
        "conv3_eye_size = 3\n",
        "conv3_eye_out = 384\n",
        "conv4_eye_size = 1\n",
        "conv4_eye_out = 64\n",
        "eye_size = 2 * 2 * 2 * conv4_eye_out\n",
        "# pathway: face\n",
        "conv1_face_size = 11\n",
        "conv1_face_out = 96\n",
        "pool_face_size = 2\n",
        "pool_face_stride = 2\n",
        "conv2_face_size = 5\n",
        "conv2_face_out = 256\n",
        "conv3_face_size = 3\n",
        "conv3_face_out = 384\n",
        "conv4_face_size = 1\n",
        "conv4_face_out = 64\n",
        "face_size = 2 * 2 * conv4_face_out\n",
        "# fc layer\n",
        "fc_eye_size = 128\n",
        "fc_face_size = 128\n",
        "fc_face_mask_size = 256\n",
        "face_face_mask_size = 128\n",
        "fc_size = 128\n",
        "fc2_size = 2\n",
        "\n",
        "c32 = 32\n",
        "c25 = 25"
      ],
      "metadata": {
        "id": "wZ97ctwBm_Sm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eye_left_input = keras.Input(shape=(img_size, img_size, n_channel), name='eye_left')\n",
        "eye_right_input = keras.Input(shape=(img_size, img_size, n_channel), name='eye_right')\n",
        "face_input = keras.Input(shape=(img_size, img_size, n_channel), name='face')\n",
        "face_mask_input = keras.Input(shape=(c25, c25), name='face_mask')\n",
        "#y = keras.layers.Input(shape=(2), name='pos')\n",
        "\n",
        "initializer = keras.initializers.RandomUniform(minval=0.05, maxval=0.15)\n",
        "eye1 = keras.layers.Conv2D(filters=96,kernel_size=11,strides=(1,1), padding=\"valid\", activation=\"relu\", use_bias=True, bias_initializer=initializer)\n",
        "eye2 = keras.layers.Conv2D(filters=256,kernel_size=5,strides=(1,1), padding=\"valid\", activation=\"relu\", use_bias=True, bias_initializer=initializer)\n",
        "eye3 = keras.layers.Conv2D(filters=384,kernel_size=3,strides=(1,1), padding=\"valid\", activation=\"relu\", use_bias=True, bias_initializer=initializer)\n",
        "eye4 = keras.layers.Conv2D(filters=64,kernel_size=1,strides=(1,1), padding=\"valid\", activation=\"relu\", use_bias=True, bias_initializer=initializer)\n",
        "\n",
        "eye_left1 = eye1(eye_left_input)\n",
        "eye_left1 = keras.layers.MaxPooling2D(pool_size=(2,2),strides=None, padding=\"valid\")(eye_left1)\n",
        "eye_left2 = eye2(eye_left1)\n",
        "eye_left2 = keras.layers.MaxPooling2D(pool_size=(2,2),strides=None, padding=\"valid\")(eye_left2)\n",
        "eye_left3 = eye3(eye_left2)\n",
        "eye_left3 = keras.layers.MaxPooling2D(pool_size=(2,2),strides=None, padding=\"valid\")(eye_left3)\n",
        "eye_left4 = eye4(eye_left3)\n",
        "eye_left4 = keras.layers.MaxPooling2D(pool_size=(2,2),strides=None, padding=\"valid\")(eye_left4)\n",
        "eye_left_out = keras.layers.Flatten()(eye_left4)\n",
        "\t\n",
        "#shouldn't use\n",
        "eye_right1 = eye1(eye_right_input)\n",
        "eye_right1 = keras.layers.MaxPooling2D(pool_size=(2,2),strides=None, padding=\"valid\")(eye_right1)\n",
        "eye_right2 = eye2(eye_right1)\n",
        "eye_right2 = keras.layers.MaxPooling2D(pool_size=(2,2),strides=None, padding=\"valid\")(eye_right2)\n",
        "eye_right3 = eye3(eye_right2)\n",
        "eye_right3 = keras.layers.MaxPooling2D(pool_size=(2,2),strides=None, padding=\"valid\")(eye_right3)\n",
        "eye_right4 = eye4(eye_right3)\n",
        "eye_right4 = keras.layers.MaxPooling2D(pool_size=(2,2),strides=None, padding=\"valid\")(eye_right4)\n",
        "eye_right_out = keras.layers.Flatten()(eye_right4)\n",
        "\n",
        "face1 = keras.layers.Conv2D(filters=96,kernel_size=11,strides=(1,1), padding=\"valid\", activation=\"relu\", use_bias=True, bias_initializer=initializer)(face_input)\n",
        "face1 = keras.layers.MaxPooling2D(pool_size=(2,2),strides=None, padding=\"valid\")(face1)\n",
        "face2 = keras.layers.Conv2D(filters=256,kernel_size=5,strides=(1,1), padding=\"valid\", activation=\"relu\", use_bias=True, bias_initializer=initializer)(face1)\n",
        "face2 = keras.layers.MaxPooling2D(pool_size=(2,2),strides=None, padding=\"valid\")(face2)\n",
        "face3 = keras.layers.Conv2D(filters=384,kernel_size=3,strides=(1,1), padding=\"valid\", activation=\"relu\", use_bias=True, bias_initializer=initializer)(face2)\n",
        "face3 = keras.layers.MaxPooling2D(pool_size=(2,2),strides=None, padding=\"valid\")(face3)\n",
        "face4 = keras.layers.Conv2D(filters=64,kernel_size=1,strides=(1,1), padding=\"valid\", activation=\"relu\", use_bias=True, bias_initializer=initializer)(face3)\n",
        "face4 = keras.layers.MaxPooling2D(pool_size=(2,2),strides=None, padding=\"valid\")(face4)\n",
        "face_out = keras.layers.Flatten()(face4)\n",
        "\t\n",
        "# fc layer\n",
        "# eye\n",
        "eyes_concat = keras.layers.Concatenate(axis=-1) ([eye_left_out, eye_right_out])\n",
        "eyes_dense_out = keras.layers.Dense(128, activation=\"relu\",use_bias=True,bias_initializer=initializer)(eyes_concat)\n",
        "# face\n",
        "face_dense = keras.layers.Dense(128, activation=\"relu\",use_bias=True,bias_initializer=initializer)(face_out)\n",
        "face_mask = keras.layers.Flatten()(face_mask_input)\n",
        "face_mask = keras.layers.Dense(256, activation=\"relu\",use_bias=True,bias_initializer=initializer)(face_mask)\n",
        "face_concat = keras.layers.Concatenate(axis=-1) ([face_dense, face_mask])\n",
        "face_dense_out = keras.layers.Dense(256, activation=\"relu\",use_bias=True,bias_initializer=initializer)(face_concat)\n",
        "# all\n",
        "concat = keras.layers.Concatenate(axis=-1) ([eyes_dense_out, face_dense_out])\n",
        "dense1 = keras.layers.Dense(128, activation=\"relu\",use_bias=True,bias_initializer=initializer)(concat)\n",
        "out = keras.layers.Dense(2, activation=\"relu\", use_bias=True,bias_initializer=initializer, name='y_output')(dense1)\n",
        "\n",
        "model = keras.Model(\n",
        "    inputs = {'eye_left':eye_left_input, \n",
        "              'eye_right':eye_right_input, \n",
        "              'face':face_input, \n",
        "              'face_mask':face_mask_input},\n",
        "    outputs = {'y_output':out},\n",
        ")\n",
        "\n",
        "model.compile(\n",
        "    optimizer = keras.optimizers.Adam(learning_rate=0.01),\n",
        "    loss = keras.losses.mean_squared_error,\n",
        ")\n",
        "\n",
        "#def train(self, train_data, val_data, lr=1e-3, batch_size=128, max_epoch=1000, min_delta=1e-4, patience=10, print_per_epoch=10, out_model='my_model'):"
      ],
      "metadata": {
        "id": "3AhiciqcnR6W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import data\n",
        "npzfile = np.load(\"/content/drive/MyDrive/Colab Notebooks/dataset/eye_tracker_train_and_val.npz\")\n",
        "train_eye_left = npzfile[\"train_eye_left\"].astype(np.float32)\n",
        "train_eye_right = npzfile[\"train_eye_right\"].astype(np.float32)\n",
        "train_face = npzfile[\"train_face\"].astype(np.float32)\n",
        "train_face_mask = npzfile[\"train_face_mask\"].astype(np.float32)\n",
        "train_y = npzfile[\"train_y\"].astype(np.float32)\n",
        "#val_eye_left = npzfile[\"val_eye_left\"]\n",
        "#val_eye_right = npzfile[\"val_eye_right\"]\n",
        "#val_face = npzfile[\"val_face\"]\n",
        "#val_face_mask = npzfile[\"val_face_mask\"]\n",
        "#val_y = npzfile[\"val_y\"]"
      ],
      "metadata": {
        "id": "Zctn5SSWnC3V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(train_eye_left.shape[0]):\n",
        "  train_eye_left[i] = train_eye_left[i]/255.\n",
        "  train_eye_right[i] = train_eye_right[i]/255.\n",
        "  train_face[i] = train_face[i]/255."
      ],
      "metadata": {
        "id": "rLpIXDs1BNqc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max=0\n",
        "min=0\n",
        "for i in range(train_y.shape[0]):\n",
        "  if train_y[i][0]>max:\n",
        "    max=train_y[i][0]\n",
        "  if train_y[i][1]>max:\n",
        "    max=train_y[i][1]\n",
        "  if train_y[i][0]<min:\n",
        "    min=train_y[i][0]\n",
        "  if train_y[i][1]<min:\n",
        "    min=train_y[i][1]\n",
        "amplitude = max+abs(min)\n",
        "for i in range(train_y.shape[0]):\n",
        "  train_y[i]=(train_y[i]+abs(min))/amplitude"
      ],
      "metadata": {
        "id": "6SDGRQ8e6lqb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gen(dim):\n",
        "  i = 0\n",
        "  while i<dim:\n",
        "    yield {'eye_left': train_eye_left[i],\n",
        "           'eye_right': train_eye_right[i],\n",
        "           'face': train_face[i],\n",
        "           'face_mask': train_face_mask[i]}, {'y_output': train_y[i]}\n",
        "    i += 1"
      ],
      "metadata": {
        "id": "kUgwrGohgLaN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dim = train_eye_left.shape[0]\n",
        "train_dataset = tf.data.Dataset.from_generator(gen, args=[dim], output_signature=(\n",
        "    {'eye_left': tf.TensorSpec(shape=(64, 64, 3), dtype=tf.float32),\n",
        "    'eye_right': tf.TensorSpec(shape=(64, 64, 3), dtype=tf.float32),\n",
        "    'face': tf.TensorSpec(shape=(64, 64, 3), dtype=tf.float32),\n",
        "    'face_mask': tf.TensorSpec(shape=(25, 25), dtype=tf.float32)},\n",
        "    {'y_output': tf.TensorSpec(shape=(2), dtype=tf.float32)}\n",
        "))"
      ],
      "metadata": {
        "id": "ADrNCsnDh1iT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(\n",
        "    train_dataset.batch(10),\n",
        "    epochs=10,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ri7XTuOjzedW",
        "outputId": "8a8685d4-3bfc-4138-beda-1a4ed410ad99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "4800/4800 [==============================] - 351s 71ms/step - loss: 1792.6218\n",
            "Epoch 2/10\n",
            " 694/4800 [===>..........................] - ETA: 4:49 - loss: 0.2324"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ab=1\n",
        "#train_dataset.take(1)\n",
        "for ab,bc in train_dataset.repeat().batch(1).take(1):\n",
        "  print(bc)\n",
        "#for i,ab, bc in gen():\n",
        " # print(i)\n",
        "  #if i>10:\n",
        "   # break"
      ],
      "metadata": {
        "id": "m56W_8G-tDRv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print (\"train_eye_left.shape\")\n",
        "print(train_eye_left.shape)\n",
        "print (\"train_eye_right.shape\")\n",
        "print(train_eye_right.shape)\n",
        "print (\"train_face.shape\")\n",
        "print(train_face.shape)\n",
        "print (\"train_face_mask.shape\")\n",
        "print(train_face_mask.shape)\n",
        "print (\"train_y.shape\")\n",
        "print(train_y.shape)"
      ],
      "metadata": {
        "id": "hPg4c5P0gjL6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize(data):\n",
        "    data = data/255. # scaling\n",
        "    data = data - np.mean(data, axis=0) # normalizing\n",
        "    return data\n",
        "\n",
        "#train_dataset = tf.data.Dataset.from_tensor_slices((train_eye_left,train_eye_right,train_face, train_face_mask, train_y))\n",
        "#val_dataset = tf.data.Dataset.from_tensor_slices((val_eye_left,val_eye_right,val_face, val_face_mask, val_y))\n",
        "\n",
        "def prepare_data(data):\n",
        "    eye_left, eye_right, face, face_mask, y = data\n",
        "    eye_left = normalize(eye_left)\n",
        "    print ('eye_left normalized')\n",
        "    eye_right = normalize(eye_right)\n",
        "    print ('eye_right normalized')\n",
        "    face = normalize(face)\n",
        "    print ('face normalized')\n",
        "    face_mask = np.reshape(face_mask, (face_mask.shape[0], -1)).astype('float32')\n",
        "    print ('face mask normalized')\n",
        "    y = y.astype('float32')\n",
        "    print ('y normalized')\n",
        "    return [eye_left, eye_right, face, face_mask, y]\n",
        "\n",
        "def shuffle_data(data):\n",
        "    idx = np.arange(data[0].shape[0])\n",
        "    np.random.shuffle(idx)\n",
        "    for i in range(len(data)):\n",
        "        data[i] = data[i][idx]\n",
        "    return data\n",
        "\n",
        "def next_batch(data, batch_size):\n",
        "    for i in np.arange(0, data[0].shape[0], batch_size):\n",
        "        # yield a tuple of the current batched data\n",
        "        yield [each[i: i + batch_size] for each in data]"
      ],
      "metadata": {
        "id": "dpANmQFYBF8C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_model(session, save_path):\n",
        "    \"\"\" Loads a saved TF model from a file.\n",
        "    Args:\n",
        "        session: The tf.Session to use.\n",
        "        save_path: The save path for the saved session, returned by Saver.save().\n",
        "    Returns:\n",
        "        The inputs placehoder and the prediction operation.\n",
        "    \"\"\"\n",
        "    print (\"Loading model from file '%s'... % save_path \")\n",
        "\n",
        "    meta_file = save_path + \".meta\"\n",
        "    if not os.path.exists(meta_file):\n",
        "        raise Exception(\"ERROR: Expected .meta file '%s', but could not find it.\" % meta_file)\n",
        "\n",
        "    saver = tf.train.import_meta_graph(meta_file)\n",
        "    # It's finicky about the save path.\n",
        "    save_path = os.path.join(\"./\", save_path)\n",
        "    saver.restore(session, save_path)\n",
        "\n",
        "    # Check that we have the handles we expected.\n",
        "    return extract_validation_handles(session)"
      ],
      "metadata": {
        "id": "sy80Ik4boNyh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}